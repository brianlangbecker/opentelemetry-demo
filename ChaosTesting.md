# Chaos Testing Scenarios - Master Index

This document provides a comprehensive index of chaos engineering and failure scenario testing capabilities in the OpenTelemetry Demo.

## Table of Contents

- [Available Scenarios](#available-scenarios)
- [Scenario Coverage Matrix](#scenario-coverage-matrix)
- [Scenarios by Category](#scenarios-by-category)
- [Planned Scenarios](#planned-scenarios)
- [Quick Start Guide](#quick-start-guide)

---

## Available Scenarios

These scenarios are **ready to use** with complete guides and require **zero code changes**.

### Memory & Resource Exhaustion

| Scenario | Guide | Method | Observable Outcome | Time to Failure |
|----------|-------|--------|-------------------|-----------------|
| **Memory Spike / Sudden Crash** | [memory-tracking-spike-crash.md](memory-tracking-spike-crash.md) | `kafkaQueueProblems: 100-2000` + 10-50 users | OOM kill, container restart, alert triggers | Configurable: slow (100-500), medium (500-1000), fast (2000) growth rates |
| **Gradual Memory Leak** | [memory-leak-gradual-checkout.md](memory-leak-gradual-checkout.md) | `kafkaQueueProblems: 200-300` + 25 users | Heap pressure, predictable growth, trend analysis | 10-20 minutes |
| **JVM GC Thrashing** | [jvm-gc-thrashing-ad-service.md](jvm-gc-thrashing-ad-service.md) | `adManualGc: on` + 50 users | Stop-the-world pauses, latency spikes, zombie service | Continuous (10s cycles) |

### Disk & Storage Pressure

| Scenario | Guide | Method | Observable Outcome | Time to Failure |
|----------|-------|--------|-------------------|-----------------|
| **Filesystem Growth / Disk Full** | [filesystem-growth-crash-simple.md](filesystem-growth-crash-simple.md) | Error flags + 50 users | OpenSearch disk grows 900MB ‚Üí 4-5GB, cluster yellow/red | 2-3 hours |
| **Postgres Disk & IOPS Pressure** | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md) | `kafkaQueueProblems: 2000` + 50 users | Database 50MB ‚Üí 3-5GB, I/O latency, cache degradation | 2-3 hours ‚ö†Ô∏è **Untested** |

### Infrastructure Failures

| Scenario | Guide | Method | Observable Outcome | Time to Failure |
|----------|-------|--------|-------------------|-----------------|
| **DNS Resolution Failure** | [dns-resolution-failure.md](dns-resolution-failure.md) | Scale CoreDNS to 0 replicas | All service calls fail with "no such host", traces have no child spans | Variable: immediate to 5 min (depends on service runtime DNS cache) |
| **DNS Capacity Issues** | [dns-insufficient-coredns.md](dns-insufficient-coredns.md) | Scale CoreDNS UP (10 replicas), populate cache, scale DOWN to 2 (80% reduction) | Mixed success/failure (50-80%), variable latency (fast/slow/timeout), CoreDNS CPU 95-100% | Gradual: 3-10 min as cache expires |

---

## Scenario Coverage Matrix

Comprehensive mapping of chaos testing scenarios to implementation status and observability:

| Scenario Type | Description | Method | Observable Signals | Status | Guide |
|---------------|-------------|--------|-------------------|--------|-------|
| **Disk Full / I/O Latency** | Fill disk with data | Postgres: `kafkaQueueProblems` / OpenSearch: error flags | Disk usage metrics, I/O wait time, query latency, cache hit ratio drop | ‚úÖ Available (Postgres: ‚ö†Ô∏è untested) | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md), [filesystem-growth-crash-simple.md](filesystem-growth-crash-simple.md) |
| **CPU / Memory Spikes or Saturation** | Drive CPU or memory to 100% | `kafkaQueueProblems: 100-2000` (adjustable) + 10-50 users | CPU/memory metrics, OOM kill, pod restart, correlated process, MTTR | ‚úÖ Available | [memory-tracking-spike-crash.md](memory-tracking-spike-crash.md) |
| **CPU Saturation (standalone)** | Drive CPU to 100% independently | `adHighCpu: on` flag | CPU utilization metrics, latency spikes, correlated process | ‚ö†Ô∏è Flag exists, needs guide | Flag available in `demo.flagd.json` |
| **Memory Leak / Heap Pressure** | Gradual memory allocation | `kafkaQueueProblems: 200-300` + moderate load | Heap trend, GC pauses, predictable failure | ‚úÖ Available | [memory-leak-gradual-checkout.md](memory-leak-gradual-checkout.md) |
| **DNS Problem** | DNS resolution failure | Stop CoreDNS / Scale to 0 replicas | DNS latency isolated as root cause, service timeouts, "no such host" errors | ‚úÖ Available | [dns-resolution-failure.md](dns-resolution-failure.md) |
| **Insufficient CoreDNS** | Reduce CoreDNS capacity | Scale CoreDNS up (10 replicas), populate cache, then scale down (1-2 replicas) | DNS lookup delays, intermittent failures, mixed success/failure, CoreDNS CPU saturation | ‚úÖ Available | [dns-insufficient-coredns.md](dns-insufficient-coredns.md) |
| **Storage I/O Constraint** | IOPS quota exhaustion | High write volume to Postgres | `blk_read_time`, `blk_write_time`, query latency | ‚úÖ Available (‚ö†Ô∏è untested) | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md) |
| **Application Crash** | Kill process/pod | Manual pod delete or `adFailure`, `cartFailure`, `paymentFailure` flags | Alert triggers, restart events, trace ends abruptly, MTTR | ‚ö†Ô∏è Flags exist, needs guide | Flags available, manual pod kill works |
| **Service Degradation** | Slow responses without crash | `imageSlowLoad`, `paymentFailure: 50%` | Latency increase, partial failures, SLO burn | ‚ö†Ô∏è Flags exist, needs guide | Flags available in `demo.flagd.json` |
| **Kafka Queue Overload** | Message backlog and lag | `kafkaQueueProblems: 100` + high load | Consumer lag, processing delays, queue depth | ‚ö†Ô∏è Implicit in other scenarios | Documented in memory scenarios |
| **Network Latency** | Slow network between services | Not implemented | Trace shows network time, service-to-service latency | üî¥ Not implemented | Requires network policy or sidecar |
| **Database Connection Exhaustion** | Max connections reached | High concurrency + sustained load | Connection pool errors, timeouts | ‚ö†Ô∏è Possible with Postgres scenario | Achievable with postgres-disk-iops-pressure |

**Legend:**
- ‚úÖ **Available** - Complete guide exists, ready to use
- ‚ö†Ô∏è **Partial** - Flag/capability exists, needs documentation
- üî¥ **Not Implemented** - Requires code/config changes

---

## Scenarios by Category

### 1. Resource Exhaustion

#### Memory

| Scenario | Target Service | Failure Pattern | Guide |
|----------|---------------|-----------------|-------|
| Sudden Memory Spike | Checkout (Go) | Exponential growth ‚Üí OOM crash | [memory-tracking-spike-crash.md](memory-tracking-spike-crash.md) |
| Gradual Memory Leak | Checkout (Go) | Linear growth ‚Üí predictable OOM | [memory-leak-gradual-checkout.md](memory-leak-gradual-checkout.md) |
| JVM Heap Pressure | Ad Service (Java) | GC thrashing ‚Üí zombie service | [jvm-gc-thrashing-ad-service.md](jvm-gc-thrashing-ad-service.md) |

**Observability:**
- Container memory metrics (working set, limit utilization)
- Heap allocation and GC metrics
- OOM events and restart counts
- Latency correlation with memory pressure

#### CPU

| Scenario | Target Service | Method | Status |
|----------|---------------|--------|--------|
| CPU Saturation | Ad Service (Java) | `adHighCpu: on` | ‚ö†Ô∏è Flag exists, needs guide |

**Observability (expected):**
- CPU utilization at 100%
- Process CPU time breakdown
- Latency spikes correlated with CPU
- Throttling events

#### Disk & Storage

| Scenario | Target | Failure Pattern | Guide |
|----------|--------|-----------------|-------|
| Log Storage Growth | OpenSearch | Accumulation ‚Üí disk full ‚Üí cluster degradation | [filesystem-growth-crash-simple.md](filesystem-growth-crash-simple.md) |
| Database Disk Growth | Postgres | Transaction volume ‚Üí disk exhaustion | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md) ‚ö†Ô∏è **Untested** |
| IOPS Pressure | Postgres | Sustained writes ‚Üí I/O saturation ‚Üí latency | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md) ‚ö†Ô∏è **Untested** |

**Observability:**
- Disk usage metrics (absolute and percentage)
- I/O wait time and throughput
- Database cache hit ratio degradation
- Query latency increase

### 2. Service Failures

#### Crashes & Restarts

| Scenario | Target Service | Method | Status |
|----------|---------------|--------|--------|
| Service Crash | Ad Service | `adFailure: on` | ‚ö†Ô∏è Flag exists |
| Service Crash | Cart Service | `cartFailure: on` | ‚ö†Ô∏è Flag exists |
| Service Crash | Payment Service | `paymentUnreachable: on` | ‚ö†Ô∏è Flag exists |
| Pod Kill | Any service | `kubectl delete pod` | ‚úÖ Manual operation |

**Observability (expected):**
- Service down alerts
- Pod/container restart events
- MTTR calculation
- Traces ending abruptly
- Fatal log entries

#### Partial Failures

| Scenario | Target Service | Method | Status |
|----------|---------------|--------|--------|
| Intermittent Failures | Payment Service | `paymentFailure: 10-100%` | ‚ö†Ô∏è Flag exists |
| Slow Responses | Image Provider | `imageSlowLoad: 5sec/10sec` | ‚ö†Ô∏è Flag exists |
| Cache Failures | Recommendation Service | `recommendationCacheFailure: on` | ‚ö†Ô∏è Flag exists |

**Observability (expected):**
- Partial error rate (n% failures)
- Latency increase without crash
- SLO burn rate
- Circuit breaker activation

### 3. Infrastructure Issues

#### Queue & Messaging

| Scenario | Target | Method | Status |
|----------|--------|--------|--------|
| Kafka Lag Spike | Kafka + Accounting | `kafkaQueueProblems: 100` | ‚ö†Ô∏è Implicit in memory scenarios |
| Message Overload | Kafka Topic | `kafkaQueueProblems: 2000` | ‚úÖ Documented in memory guides |

**Observability:**
- Consumer lag metrics
- Queue depth
- Processing delays
- Backpressure effects

#### Network & DNS

| Scenario | Method | Status | Guide |
|----------|--------|--------|-------|
| DNS Resolution Failure | Stop CoreDNS (scale to 0) | ‚úÖ Available | [dns-resolution-failure.md](dns-resolution-failure.md) |
| DNS Capacity Issue / Insufficient CoreDNS | Scale CoreDNS up (10), populate cache, scale down (1-2) - 80% reduction | ‚úÖ Available | [dns-insufficient-coredns.md](dns-insufficient-coredns.md) |
| Network Latency | Chaos mesh / network policy | üî¥ Not implemented | Requires additional tooling |

**Observability:**
- **Complete DNS Failure:** "no such host" errors, 100% failure rate, uniform timeout (~5s), traces with no child spans
- **DNS Capacity Issues:** Mixed success/failure (50-80%), variable latency (fast cached ‚Üí slow queued ‚Üí timeout), CoreDNS CPU at 95-100%, three distinct latency bands in heatmap
- Error messages without IP addresses (DNS never resolved)

### 4. Database Issues

**Note:** See [verify-postgres.md](verify-postgres.md) for comprehensive verification that Postgres is running and receiving data.

| Scenario | Database | Method | Guide |
|----------|----------|--------|-------|
| Disk Exhaustion | Postgres | High transaction volume | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md) ‚ö†Ô∏è **Untested** |
| IOPS Saturation | Postgres | Sustained writes | [postgres-disk-iops-pressure.md](postgres-disk-iops-pressure.md) ‚ö†Ô∏è **Untested** |
| Connection Exhaustion | Postgres | High concurrency | ‚ö†Ô∏è Achievable with Postgres scenario (untested) |
| Cache Degradation | Postgres | Large dataset + limited memory | ‚ö†Ô∏è Documented in Postgres guide (untested) |

**Observability:**
- Database size and table growth
- I/O metrics (read/write time)
- Cache hit ratio
- Connection pool utilization
- Query latency trends

---

## Planned Scenarios

These scenarios require additional implementation:

### High Priority

| Scenario | Implementation Needed | Estimated Complexity |
|----------|----------------------|---------------------|
| **Application Crash Guide** | Documentation only (flags exist: `adFailure`, `cartFailure`, etc.) | Low - 2 hours |
| **Service Degradation Guide** | Documentation only (flags exist: `paymentFailure`, `imageSlowLoad`) | Medium - 3 hours |
| **CPU Saturation (standalone) Guide** | Documentation only (flag exists: `adHighCpu`) | Low - 1 hour |

### Medium Priority

| Scenario | Implementation Needed | Estimated Complexity |
|----------|----------------------|---------------------|
| **Network Latency** | Chaos Mesh or Istio fault injection | High - requires additional tooling |
| **Connection Pool Exhaustion** | Enhanced load testing against Postgres | Medium - extend existing scenario |
| **DNS Capacity Issue (formalize guide)** | Document the scale-up-then-down technique as separate section | Low - technique already exists |

### Low Priority

| Scenario | Implementation Needed | Estimated Complexity |
|----------|----------------------|---------------------|
| **Certificate Expiration** | Mock cert expiration mechanism | High - requires TLS setup |
| **Rate Limiting** | Add rate limiter to services | Medium - code changes required |
| **Cascading Failures** | Orchestrated multi-service failure | Medium - complex scenario |

---

## Quick Start Guide

### 1. Choose Your Scenario

**For Rapid Testing (configurable timing):**
- [Memory Spike](memory-tracking-spike-crash.md) - Adjustable growth rate: slow (100-500), medium (500-1000), fast (2000) by lowering `kafkaQueueProblems` value
- [JVM GC Thrashing](jvm-gc-thrashing-ad-service.md) - Immediate cyclical degradation

**For Gradual Observation (10-30 minutes):**
- [Gradual Memory Leak](memory-leak-gradual-checkout.md) - 10-20 minutes to OOM

**For Long-Term Trends (hours):**
- [Filesystem Growth](filesystem-growth-crash-simple.md) - 2-3 hours for significant growth
- [Postgres Disk/IOPS](postgres-disk-iops-pressure.md) - 2-3 hours for I/O pressure ‚ö†Ô∏è **Untested**

### 2. Prerequisites

All scenarios require:
- ‚úÖ OpenTelemetry Demo running
- ‚úÖ Telemetry configured to send to Honeycomb
- ‚úÖ Access to FlagD UI (http://localhost:4000)
- ‚úÖ Access to Locust UI (http://localhost:8089)

### 3. Common Workflow

**Step 1:** Read the scenario guide
**Step 2:** Enable feature flag in FlagD UI
**Step 3:** Generate load in Locust
**Step 4:** Monitor in Honeycomb
**Step 5:** Clean up (disable flag, stop load)

### 4. Flag Quick Reference

| Flag | Effect | Scenarios Using It |
|------|--------|-------------------|
| `kafkaQueueProblems` | Kafka message flood | Memory spike, memory leak, Postgres disk |
| `adManualGc` | JVM GC thrashing | JVM GC scenario |
| `adHighCpu` | CPU saturation | (needs guide) |
| `adFailure` | Ad service crash | (needs guide) |
| `cartFailure` | Cart service crash | (needs guide) |
| `paymentFailure` | Payment errors (0-100%) | (needs guide) |
| `paymentUnreachable` | Payment service down | (needs guide) |
| `imageSlowLoad` | Slow image loading | (needs guide) |
| `loadGeneratorFloodHomepage` | Frontend overload | (needs guide) |
| `recommendationCacheFailure` | Cache failures | (needs guide) |
| `productCatalogFailure` | Product errors | (needs guide) |

---

## Observability Patterns

### Metrics to Monitor

**Resource Metrics:**
- `k8s.pod.memory.working_set` - Current memory usage
- `k8s.pod.memory_limit_utilization` - Memory as % of limit
- `k8s.pod.cpu_utilization` - CPU usage
- `k8s.pod.ephemeral-storage.used` - Disk usage

**Application Metrics:**
- `jvm.memory.used` - JVM heap usage (Java services)
- `jvm.gc.duration` - Garbage collection time
- `process.runtime.go.mem.heap_alloc` - Go heap allocation
- `process.runtime.go.goroutines` - Goroutine count

**Database Metrics:**
- `db.io.read_bytes`, `db.io.write_bytes` - Database I/O
- Cache hit ratio (from `pg_stat_database`)
- Table sizes and row counts
- Connection pool utilization

**Service Metrics:**
- Request rate (`COUNT`)
- Latency percentiles (`P50`, `P95`, `P99`)
- Error rate (`otel.status_code`)
- Trace completion vs. abandonment

### Honeycomb Query Patterns

**Resource Pressure:**
```
WHERE k8s.pod.name STARTS_WITH <service>
VISUALIZE MAX(<metric>)
GROUP BY time(30s)
```

**Service Degradation:**
```
WHERE service.name = <service>
VISUALIZE P95(duration_ms), P99(duration_ms)
GROUP BY time(1m)
```

**Error Analysis:**
```
WHERE service.name = <service>
VISUALIZE COUNT
GROUP BY otel.status_code
```

**Trace Investigation:**
```
WHERE service.name = <service> AND duration_ms > <threshold>
VISUALIZE TRACES
ORDER BY duration_ms DESC
```

---

## Contributing New Scenarios

Want to add a new chaos testing scenario? Follow these guidelines:

### 1. Scenario Documentation Template

Each scenario guide should include:
- **Overview** - Use case summary
- **Prerequisites** - Required setup
- **How It Works** - Technical explanation
- **Execution Steps** - Step-by-step instructions (Docker + Kubernetes)
- **Monitoring Queries** - 10+ Honeycomb queries
- **Dashboard Configuration** - Multi-panel setup
- **Expected Timeline** - Time-based progression
- **Alert Configuration** - Alerting thresholds
- **Trace Correlation** - Example trace analysis
- **Troubleshooting** - Common issues
- **Cleanup** - How to reset

### 2. Naming Convention

- Use lowercase with hyphens: `scenario-name-target-service.md`
- Be descriptive: `postgres-disk-iops-pressure.md` not `db-test.md`
- Include target service when applicable

### 3. Update This Index

When adding a scenario:
1. Add row to **Scenario Coverage Matrix**
2. Add to appropriate **Scenarios by Category** section
3. Update **Flag Quick Reference** if using new flags
4. Update main [README.md](README.md) scenario list

### 4. Testing Checklist

Before submitting:
- [ ] Tested on Docker Compose
- [ ] Tested on Kubernetes
- [ ] Honeycomb queries verified
- [ ] Screenshots captured (optional)
- [ ] Timeline documented with actual results
- [ ] Cleanup steps verified

---

## Support & Feedback

- **OpenTelemetry Demo Issues:** https://github.com/open-telemetry/opentelemetry-demo/issues
- **Honeycomb Documentation:** https://docs.honeycomb.io
- **Slack:** [CNCF Slack #otel-demo](https://cloud-native.slack.com/archives/C03B4CWV4DA)

---

## References

- [OpenTelemetry Demo Documentation](https://opentelemetry.io/docs/demo/)
- [Chaos Engineering Principles](https://principlesofchaos.org/)
- [Site Reliability Engineering (SRE)](https://sre.google/)
- [Honeycomb Observability](https://www.honeycomb.io/blog)

---

**Last Updated:** 2025-10-26

**Scenario Count:**
- ‚úÖ Available: 7 scenarios (Memory spike, Gradual leak, JVM GC, Filesystem growth, Postgres disk/IOPS [‚ö†Ô∏è untested], DNS failure)
- ‚ö†Ô∏è Partial: 6 scenarios (DNS capacity variation technique documented; flags exist for crash/degradation guides)
- üî¥ Not Implemented: 1 scenario (network latency - requires additional tooling)
